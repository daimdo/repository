{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pandas library Overview\n",
    "Python library designed for data manipulation and analysis. It provides \n",
    "high-performance, easy-to-use data structures and data analysis tools and has \n",
    "functions for analyzing, cleaning, exploring, and manipulating data. It also\n",
    "handles various data formats (CSV, Excel, SQL databases, etc.) and simplifies \n",
    "complex data manipulation tasks and empowers users to extract valuable insights \n",
    "from their data.\n",
    "\n",
    "If Python and PIP are already installed on a system, install pandas using this \n",
    "command:\n",
    "pip install pandas\n",
    "Pandas is usually imported under the pd alias.\n",
    "import pandas as pd\n",
    "The version string is stored under __version__ attribute.\n",
    "print(pd.__version__)\n",
    "\n",
    "\n",
    "Why Use Pandas?\n",
    "Pandas allows us to analyze big data and make conclusions based on statistical \n",
    "theories. Pandas can clean messy data sets, and make them readable and relevant.\n",
    "\n",
    "Efficient Data Structures: introduces Series and DataFrame objects, optimized\n",
    "for handling large datasets efficiently.\n",
    "\n",
    "Data Cleaning and Preprocessing: provides tools to handle missing values, \n",
    "duplicates, outliers, and inconsistencies in data. It simplifies the process of \n",
    "transforming raw data into a clean and usable format.\n",
    "\n",
    "Data Analysis and Exploration: offers functions for statistical analysis, \n",
    "aggregation, grouping, and pivoting data. It allows to explore data patterns, \n",
    "relationships, and trends easily.\n",
    "\n",
    "Integration with Other Libraries: seamlessly integrates with other popular data \n",
    "science libraries like NumPy, Matplotlib, and Scikit-learn, enabling end-to-end \n",
    "data analysis and machine learning workflows.\n",
    "\n",
    "Time Series Analysis: Pandas excels at handling time series data, offering \n",
    "functionalities for resampling, frequency conversion, and time-based \n",
    "calculations.\n",
    "\n",
    "\n",
    "What Can Pandas Do?\n",
    "Import data from various sources: CSV, Excel, SQL databases, and more.\n",
    "Create, manipulate, and analyze data frames: Perform operations like filtering, \n",
    "sorting, grouping, and aggregation.\n",
    "Handle missing data: Fill missing values, drop missing rows or columns.\n",
    "Explore data: Calculate summary statistics, visualize data distributions.\n",
    "Prepare data for machine learning: Feature engineering, normalization, and \n",
    "scaling.\n",
    "Time series analysis: Handle time-indexed data, perform forecasting and \n",
    "analysis.\n",
    "Data visualization: Create plots and charts to understand data patterns.\n",
    "\n",
    "In essence, Pandas empowers data scientists and analysts to efficiently explore, \n",
    "clean, transform, and analyze data, making it a valuable tool for data-driven \n",
    "decision making.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pandas Series\n",
    "Series is a one-dimensional array holding data of any type, like a column in a \n",
    "table.\n",
    "\"\"\"\n",
    "# Create a simple Pandas Series from a list:\n",
    "s = [1,10,2000]\n",
    "ps = pd.Series(s)\n",
    "print(ps, \"\\n\")\n",
    "\"\"\"Output\n",
    ">>>0       1\n",
    "   1      10\n",
    "   2    2000\n",
    "   dtype: int64\n",
    "Output shows a one-dimensional labeled array-like object (Pandas Series).\n",
    "The values from the original list s as the data.\n",
    "An index assigned to each value (0, 1, 2 in this case).\n",
    "The data type of the values (in this case, int64 for 64-bit integers).\n",
    "\n",
    "If nothing else is specified, the values are labeled with their index number. \n",
    "First value has index 0, second value has index 1 etc. This label can be used to \n",
    "access a specified value.\n",
    "\"\"\"\n",
    "\n",
    "# Return the first value of the Series:\n",
    "print(ps[0], \"\\n\")\n",
    "\n",
    "# With the index argument, own labels can be named after which they can be\n",
    "# referred to. E.g.\n",
    "s = [1,10,2000]\n",
    "ps = pd.Series(s, index= [\"a\", \"b\", \"c\"])\n",
    "print(ps[\"c\"], \"\\n\")\n",
    "\n",
    "\"\"\"Key/Value Objects as Series\n",
    "When creating a Series, key/value objects (like a dictionary) are also used. The \n",
    "keys of the dictionary become the labels. To select only some of the items in \n",
    "the dictionary, use the index argument and specify only the items you want to \n",
    "include in the Series.\n",
    "\"\"\"\n",
    "# Create a simple Pandas Series from a dictionary:\n",
    "calories = {\"day1\": 420, \"day2\": 380, \"day3\": 390}\n",
    "myvar = pd.Series(calories, index= [\"day1\", \"day3\"])\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pandas DataFrames\n",
    "A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional \n",
    "array, or a table with rows and columns. \n",
    "\n",
    "Pandas Series vs. DataFrame\n",
    "Pandas Series\n",
    "One-dimensional labeled array.\n",
    "Similar to a NumPy array but with index labels.\n",
    "Can hold any data type (numbers, strings, objects).\n",
    "Think of it as a single column of a spreadsheet.\n",
    "\n",
    "Pandas DataFrame\n",
    "Two-dimensional labeled data structure.\n",
    "Consists of multiple columns, each of which is a Series.\n",
    "Columns can have different data types.\n",
    "Similar to a spreadsheet or a SQL table.\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    \"category\": [1,2,3],\n",
    "    \"amount\": [100,200,300]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df, \"\\n\")\n",
    "\n",
    "print(df.loc[0], \"\\n\")\n",
    "# Selects a single row with index label 0.\n",
    "# Returns a Pandas Series, as it's a single row of data from the DataFrame.\n",
    "\n",
    "print(df.loc[[0, 1]], \"\\n\")\n",
    "# Selects multiple rows with index labels 0 and 1.\n",
    "# Returns Pandas DataFrame, maintaining tabular structure with multiple rows.\n",
    "\n",
    "# Named Indexes\n",
    "# With the index argument, you can name your own indexes.\n",
    "data = {\n",
    "    \"category\": [1,2,3],\n",
    "    \"amount\": [100,200,300]\n",
    "}\n",
    "df = pd.DataFrame(data, index= [\"day 1\", \"day 2\", \"day 3\"])\n",
    "print(df, \"\\n\")\n",
    "# Locate Named Indexes\n",
    "# Use the named index in the loc attribute to return the specified row(s).\n",
    "print(df.loc[\"day 2\"], \"\\n\")\n",
    "print(df.loc[[\"day 1\", \"day 3\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Files in DataFrames\n",
    "Load Files Into a DataFrame\n",
    "If your data sets are stored in a file, Pandas can load them into a DataFrame.\n",
    "\n",
    "Read CSV Files\n",
    "A simple way to store big data sets is to use CSV files (comma separated files).\n",
    "\n",
    "Load a comma separated file (CSV file) into a DataFrame (make sure it's in the\n",
    "same directory as your code, or specified in the code it's stored elsewhere):\n",
    "df = pd.read_csv('data.csv') #data.csv is just an example here\n",
    "print(df) \n",
    ">>>Duration  Pulse  Maxpulse  Calories\n",
    "          0          60    110       130     409.1\n",
    "          1          60    117       145     479.0\n",
    "\n",
    "print(df)\n",
    "Provides a concise representation of the DataFrame, often showing only a portion \n",
    "of the data due to display limitations.\n",
    "The exact output depends on the DataFrame's size and the default display \n",
    "settings of your environment (e.g., Jupyter Notebook, terminal).\n",
    "It's suitable for quick overviews of small to medium-sized DataFrames.\n",
    "To change the maximum amount of rows visualized by the print() statement, use \n",
    "pd.options.display.max_rows = 1000 for 1000 rows to be visualized.\n",
    "\n",
    "print(df.to_string())\n",
    "Provides a full string representation of the entire DataFrame, including all \n",
    "rows and columns.\n",
    "Offers more control over the output format through optional parameters like \n",
    "max_rows, max_cols, index, etc.\n",
    "Useful when you need to see the complete DataFrame or when you want to customize \n",
    "the display.\n",
    "\n",
    "Read JSON\n",
    "Big data sets are often stored, or extracted as JSON. JSON is plain text, but \n",
    "has the format of an object. JSON objects have the same format as Python \n",
    "dictionaries.\n",
    "df = pd.read_json('data.json')\n",
    "\"\"\"\n",
    "\n",
    "# Load a Python Dictionary into a DataFrame:\n",
    "data = {\n",
    "    \"Duration\": {0: 60, 1: 60},\n",
    "    \"Pulse\": {0: 110, 1: 117},\n",
    "    \"Maxpulse\": {0: 130, 1: 145},\n",
    "    \"Calories\": {0: 409, 1: 479}\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Analyzing and Cleaning Data \n",
    "Viewing the Data\n",
    "The head() method is used for getting a quick overview of the DataFrame. It \n",
    "returns the headers and a specified number of rows, starting from the top. If\n",
    "the number of rows isn't specified, the head() method returns the top 5 rows.\n",
    "Print the first 10 rows of the DataFrame:\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.head(10))\n",
    "\n",
    "The tail() method returns the headers and a specified number of rows, starting \n",
    "from the bottom.\n",
    "Print the last 5 rows of the DataFrame:\n",
    "print(df.tail()) \n",
    "\n",
    "Info About the Data\n",
    "The method info() gives more information about the data set. \n",
    "\n",
    "print(df.info())\n",
    ">>>RangeIndex: 169 entries (rows), 0 to 168\n",
    "Data columns (total 4 columns):\n",
    " #   Column    Non-Null Count  Dtype\n",
    "---  ------    --------------  -----\n",
    " 0   Duration  169 non-null    int64\n",
    " 1   Pulse     169 non-null    int64\n",
    " 2   Maxpulse  169 non-null    int64\n",
    " 3   Calories  164 non-null    float64\n",
    "dtypes: float64(1), int64(3)\n",
    "memory usage: 5.4 KB\n",
    "None \n",
    "\n",
    "Data cleaning means fixing bad data in your data set.\n",
    "Bad data could be:\n",
    "Empty cells\n",
    "Data in wrong format\n",
    "Wrong data\n",
    "Duplicates\n",
    "\"\"\"\n",
    "\n",
    "# For the upcoming examples, use this dataframe\n",
    "datacleaning = {\n",
    "    \"Duration\": {0: 110, 1: 60, 2: 45, 3: 1, 4: 55},\n",
    "    \"Pulse\": {0: 110, 1: 117, 2: 105, 3: 112, 4: 120},\n",
    "    \"Maxpulse\": {0: 130, 1: 145, 2: 135, 3: \"text\", 4: 150},\n",
    "    \"Calories\": {0: 409, 1: 479, 2: 300, 3: 350, 4: 400}\n",
    "}\n",
    "\n",
    "dfcleaning = pd.DataFrame(datacleaning)\n",
    "dfcleaning.at[0, 'Calories'] = None\n",
    "dfcleaning.at[1, 'Pulse'] = None\n",
    "print(dfcleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Cleaning Data\n",
    "Empty cells can potentially give you a wrong result when you analyze data. \n",
    "\n",
    "Remove rows\n",
    "One way to deal with empty cells is to remove rows that contain empty cells. By \n",
    "default, the dropna() method returns a new DataFrame, and will not change the \n",
    "original. \n",
    "\n",
    "Replace Empty Values\n",
    "Another way of dealing with empty cells is to insert a new value instead. The \n",
    "fillna() method allows replacing empty cells with a value\n",
    "\n",
    "Replace Using Mean, Median, or Mode\n",
    "A common way to replace empty cells, is to calculate the mean, median or mode \n",
    "value of the column. Pandas uses the mean() median() and mode() methods to \n",
    "calculate the respective values for a specified column\n",
    "\n",
    "Data of Wrong Format\n",
    "Cells with data of wrong format can make it difficult, or even impossible, to \n",
    "analyze data. To fix it, you have two options: remove the rows, or convert all \n",
    "cells in the columns into the same format.\n",
    "\n",
    "Wrong Data\n",
    "\"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", it can just be \n",
    "wrong, like if someone registered \"199\" instead of \"1.99\". Sometimes you can \n",
    "spot wrong data by looking at the data set, because you have an expectation of \n",
    "what it should be.\n",
    "For small data sets you might be able to replace the wrong data one by one, but \n",
    "not for big data sets.\n",
    "\n",
    "To replace wrong data for larger data sets you can create some rules, e.g. set \n",
    "some boundaries for legal values, and replace any values that are outside of the \n",
    "boundaries.\n",
    "\n",
    "Discovering Duplicates\n",
    "Duplicate rows are rows that have been registered more than one time. To \n",
    "discover duplicates, we can use the duplicated() method. The duplicated() method \n",
    "returns a Boolean values for each row. To remove duplicates, use the \n",
    "drop_duplicates() method.\n",
    "\"\"\"\n",
    "\n",
    "# Create a copy of dfcleaning for transformations\n",
    "new_df = dfcleaning.copy()\n",
    "replace_value = 130\n",
    "x = dfcleaning[\"Pulse\"].mean()  # sum of all values divided by number of values\n",
    "y = dfcleaning[\"Pulse\"].median()  # value in the middle, after all values are\n",
    "# sorted in ascending order\n",
    "z = dfcleaning[\"Pulse\"].mode()  # value that appears most frequently\n",
    "\n",
    "# Return a new Data Frame with no empty cells:\n",
    "# new_df = dfcleaning.dropna()\n",
    "# Remove all the rows containing NULL values from the original\n",
    "# dfcleaning.dropna(inplace=True)\n",
    "\n",
    "# Replace all NULL values in the existing dataframe with the number 130:\n",
    "# dfcleaning.fillna(130,inplace=True)\n",
    "# To only replace empty values for one column, specify the column name\n",
    "new_df.fillna({\"Calories\": replace_value}, inplace=True)\n",
    "\n",
    "# Calculate the MEAN/MEDIAN/MODE, and replace any empty values with it.\n",
    "new_df.fillna({\"Pulse\": z}, inplace=True)\n",
    "# In this example, even if there were multiple modes in the 'Calories' column,\n",
    "# mode()[0] would ensure that only the first mode is used to fill the missing\n",
    "# values.\n",
    "\n",
    "# Convert 'Maxpulse' to numeric, coercing errors to NaN, then fill NaN with 130\n",
    "new_df[\"Maxpulse\"] = pd.to_numeric(\n",
    "    dfcleaning[\"Maxpulse\"], errors=\"coerce\").fillna(130)\n",
    "\n",
    "# Convert \"Duration\" = 50 in row 3 to 100 in a small dataset\n",
    "new_df.loc[3, \"Duration\"] = 100\n",
    "# Convert \"Calories\" < 400 to 400 in a large dataset\n",
    "for valloc in new_df.index:\n",
    "    if new_df.loc[valloc, \"Calories\"] < 350:\n",
    "        new_df.loc[valloc, \"Calories\"] = 400\n",
    "# Delete rows where \"Maxpulse\" is 150:\n",
    "for valdrop in new_df.index:\n",
    "    if new_df.loc[valdrop, \"Maxpulse\"] == 150:\n",
    "        new_df.drop(valdrop, inplace=True)\n",
    "\n",
    "print(dfcleaning, \"\\n\")\n",
    "print(new_df, \"\\n\")\n",
    "# Output booleans showing duplicates in the dataframe\n",
    "print(new_df.duplicated(), \"\\n\")\n",
    "# Drop duplicates based on the 'Calories' column\n",
    "new_df.drop_duplicates(subset=[\"Calories\"], inplace=True)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Correlations\n",
    "Finding Relationships\n",
    "The corr() method calculates the relationship between each column in a data set.\n",
    "The Result of the corr() method is a table representing how well the \n",
    "relationship is between two columns. The number varies from -1 to 1.\n",
    "1: Perfect positive correlation. As one variable increases, the other variable \n",
    "increases proportionally.\n",
    "0: No correlation. There is no linear relationship between the variables.\n",
    "-1: Perfect negative correlation. As one variable increases, the other variable \n",
    "decreases proportionally.\n",
    "\n",
    "Interpreting Correlation Values\n",
    "Strong Positive Correlation (0.7 to 1):\n",
    "Indicates a strong linear relationship where both vars move the same direction.\n",
    "Example: Height and weight in a population.\n",
    "\n",
    "Moderate Positive Correlation (0.3 to 0.7):\n",
    "Indicates a moderate linear relationship where both variables tend to move in \n",
    "the same direction, but not perfectly.\n",
    "Example: Advertising spend and sales revenue.\n",
    "\n",
    "Weak Positive Correlation (0 to 0.3):\n",
    "Indicates a weak linear relationship where both variables slightly move in the \n",
    "same direction.\n",
    "Example: Hours of study and exam scores (if other factors are also influencing \n",
    "the scores).\n",
    "\n",
    "No Correlation (around 0):\n",
    "Indicates no linear relationship between the variables.\n",
    "Example: Shoe size and intelligence.\n",
    "\n",
    "Weak Negative Correlation (0 to -0.3):\n",
    "Indicates a weak linear relationship where one variable slightly decreases as \n",
    "the other increases.\n",
    "Example: Age of a car and its value.\n",
    "\n",
    "Moderate Negative Correlation (-0.3 to -0.7):\n",
    "Indicates a moderate linear relationship where one variable tends to decrease as \n",
    "the other increases.\n",
    "Example: Distance from city center and property prices.\n",
    "\n",
    "Strong Negative Correlation (-0.7 to -1):\n",
    "Indicates a strong linear relationship where one variable decreases as the other \n",
    "increases.\n",
    "Example: Amount of exercise and body fat percentage.\n",
    "\"\"\"\n",
    "\n",
    "print(new_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plotting\n",
    "Pandas uses the plot() method to create diagrams. We can use Pyplot, a submodule \n",
    "of the Matplotlib library to visualize the diagram on the screen.\n",
    "\n",
    "Scatter Plot\n",
    "Specify that you want a scatter plot with the kind argument:\n",
    "kind = \"scatter\"\n",
    "A scatter plot needs an x- and a y-axis.\n",
    "In the example below we will use \"Duration\" for the x-axis and \"Calories\" for \n",
    "the y-axis.\n",
    "Include the x and y arguments like this:\n",
    "x = \"Duration\", y = \"Calories\"\n",
    "\n",
    "Histogram\n",
    "Use the kind argument to specify that you want a histogram:\n",
    "kind = \"hist\"\n",
    "A histogram needs only one column and shows the frequency of each interval, e.g. \n",
    "how many workouts lasted between 50 and 60 minutes?\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "new_df.plot()\n",
    "# Scatter plot\n",
    "new_df.plot(kind=\"scatter\", x=\"Maxpulse\", y=\"Calories\")\n",
    "# Histogram\n",
    "new_df[\"Maxpulse\"].plot(kind=\"hist\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
